---
title: "EDA Notebook Analysis"
output: html_document
date: "2025-07-17"
Author: Yumeng Tan, Sherelle Li, Rom Zuckerman
---
### Heart Attack Exploratory Data Analysis

**Team Members**: Yumeng Tan, Sherelle Li, Rom Zuckerman

### I. INTRODUCTION:

#### 1) Introducing the Dataset

  The dataset used in this analysis comes from the 2015 Behavioral Risk Factor Surveillance System (BRFSS)—a nationwide health survey conducted by the Centers for Disease Control and Prevention (CDC) in collaboration with U.S. states and territories. For simplicity, we will refer to it as BRFSS throughout the analysis. The 2015 BRFSS includes 330 columns and 441,456 observations. Data are collected annually through telephone interviews, both landline and cellular, targeting adults aged 18 and older living in noninstitutionalized, community-based settings.

  The primary objective of BRFSS is to monitor health-related risk behaviors, chronic conditions, and use of preventive services across the U.S. population. In 2015, the survey was administered in all 50 states, the District of Columbia, Puerto Rico, and Guam—producing one of the most comprehensive public datasets on health behaviors. The data are weighted to reflect state-level populations and are widely used by public health officials to guide policy decisions, allocate resources, and track trends over time. 

  From an ethical standpoint, BRFSS adheres to rigorous protocols to protect respondent confidentiality. All data are fully de-identified prior to public release and reported only at the aggregate level. Although the dataset is exempt from formal Institutional Review Board (IRB) oversight due to its public and anonymized nature, we strive to approach the analysis with care to avoid misinterpretation or overgeneralization, particularly when examining outcomes for vulnerable or underrepresented populations.
<br><br>

#### 2) Description of Selected Variables

- **HeartAttack**: Whether the respondent has ever been told they had a heart attack (myocardial infarction).  
  - 1 = Yes - 2 = No   

- **SEX**: Biological sex of the respondent.  
  - 1 = Male - 2 = Female  

- **INCOME**: Annual household income from all sources, in categorical brackets.  
  - 1–8 = Ranges from < $10,000 to ≥ $75,000  

- **RACE**: Race group (recoded into 5 categories).  
  - 1 = White only - 2 = Black only - 3 = Other race only - 4 = Multiracial - 5 = Hispanic

- **AGE**: Imported Age  
  - Discrete numeric variable  

- **BMI_Num**: Body Mass Index (BMI), calculated as BMI × 100.  
  - Continuous variable: Divide by 100 to get actual BMI  

- **BMI_Cat**: BMI category based on X_BMI5.  
  - 1 = Underweight - 2 = Normal weight - 3 = Overweight - 4 = Obese  

- **HealthCare**: Whether respondent currently has any health care coverage.  
  - 1 = Yes - 2 = No 
<br><br>

#### 3) Research Interest

  We focus on the 2015 BRFSS dataset ([BRFSS 2015 Dataset](https://www.kaggle.com/datasets/cdc/behavioral-risk-factor-surveillance-system/data) in this analysis for both practical and historical reasons. As BRFSS is a repeated annual survey, selecting a past year like 2015 allows us to lay the groundwork for decade-long comparisons with newer datasets, such as the 2025 BRFSS. Notably, more recent datasets have limitations in coverage. For example, the 2023 dataset lacks data from several large states, including Pennsylvania and Kentucky, potentially compromising the representativeness and completeness of national estimates.

  In addition, BRFSS datasets from 2016 onward has been modified to comply with Trump executive orders, including adjustments in how federal health agencies presented and coded data—especially regarding race, ethnicity, and health equity. While some of these changes aimed to improve data transparency, and alignment with federal guidelines, they also introduced inconsistencies in demographic variables that can complicate subgroup comparisons and make patterns harder to interpret.

  By contrast, the 2015 dataset offers a more stable and widely used structure, making it easier to replicate established methods and ensure interpretability. It also predates politically motivated changes in public health messaging, which is important when exploring socially sensitive outcomes like cardiovascular disease risk across race and income groups.

  In this project, we specifically focus on **heart attack** (variable: `CVDINFR4`) as the response variable, rather than broader cardiovascular conditions such as **angina or coronary heart disease** (`CVDCRHD4`). This decision is based on several factors:

- **Higher prevalence**: In the 2015 dataset, there are more reported cases of heart attack than angina or CHD, giving us more statistical power.

- **Clinical severity**: Heart attacks are typically more immediately life-threatening and often require urgent medical care, making them a strong marker of cardiovascular crisis.([NIH](https://www.nhlbi.nih.gov/health/heart-attack)).

* **Distinct diagnosis**: It is possible to experience a heart attack without a prior diagnosis of coronary heart disease, so using heart attack as a primary outcome helps avoid selection bias based on access to preventive diagnostics ([Cleveland Clinic](https://my.clevelandclinic.org/health/diseases/16818-heart-attack-myocardial-infarction)).

- **Public health significance**: According to the CDC, heart attacks contribute to roughly one in every five deaths from cardiovascular disease in the U.S., emphasizing their impact on morbidity and mortality ([CDC, 2023](https://www.cdc.gov/heartdisease/facts.htm)).

  By focusing on heart attacks, we aim to investigate behavioral and demographic risk factors associated with this critical health outcome and identify population groups that may benefit most from targeted interventions.
<br><br>

### II. Dataset Manipulation

#### 1) Selecting Response Variables and Predictors

1. We set up the environment and install the packages necessary for our data analysis below. We load all the installed packages above to make the functions within them avaialble to use in our script.

```{r}
# Load libraries
library(ggplot2)
library(car)
library(carData)
library(ResourceSelection)
library(pROC)
library(dplyr)
library(emmeans)
library(ggeffects)
```
<br><br>

2. We load our original dataset **2015.csv** into R Studio. Then we select our response variable **CVDINFR4** and 9 relevant predictors to a new dataframe for the following set of data analysis.

```{r}
#Load original dataset
df <- read.csv("~/Documents/GitHub/EDA_Project/data/2015.csv")
```

```{r}
#Select relevant predictors and dependent variable
df1 <- df[, c("CVDINFR4", "SEX", "INCOME2", "X_RACEGR3", "X_AGEG5YR", "X_AGE80", "X_BMI5",
              "X_BMI5CAT", "BPHIGH4", "HLTHPLN1", "EXERANY2")]
```
<br><br>

#### 2) Recoding Variables

Among 10 variables, 8 of them are categorical variables stored in numbers. Thus, we first redefine the predictors to their corresponding categorical levels for a clearer representation Then we rename our predictors to make their names more comprehensible. By using the factor() function and specifying our own labels, we rename and redefine our selected variables.

```{r}
# Recode CVDINFR4
df1$CVDINFR4[df1$CVDINFR4 %in% c(7, 9)] <- NA
df1$HeartAttack <- ifelse(df1$CVDINFR4 == 1, 1,
                          ifelse(df1$CVDINFR4 == 2, 0, NA))
df1$HeartAttack <- factor(df1$HeartAttack, levels = c(0, 1), labels = c("No", "Yes"))

# Recode SEX
df1$SEX <- factor(df1$SEX, levels = c(1, 2), labels = c("Male", "Female"))

# Recode INCOME2
df1$INCOME2[df1$INCOME2 %in% c(77, 99)] <- NA
df1$INCOME <- factor(df1$INCOME2, levels = c(1:8),
                      labels = c("<$10k", "$10-15k", "$15-20k", "$20-25k", "$25-35k",
                                 "$35-50k", "$50-75k", ">=75k"))

# Recode _RACEGR3 as factor with appropriate labels
df1$`X_RACEGR3`[df1$`X_RACEGR3` == 9] <- NA
df1$RACE <- factor(df1$`X_RACEGR3`,
                         levels = c(1:5),
                         labels = c("White", "Black", "Other",
                                    "Multiracial", "Hispanic"))

# Recode _AGEG5YR
df1$AGE <- factor(df1$`X_AGEG5YR`, levels = 1:13,
                         labels = c("18–24", "25–29", "30–34", "35–39", "40–44", "45–49",
                                    "50–54", "55–59", "60–64", "65–69", "70–74", "75–79", "80+"))

# Recode _AGE80 
names(df1)[names(df1) == "X_AGE80"] <- "AGE_Num"

# Recode _BMI5 
df1$`X_BMI5`[df1$`X_BMI5` == 9999] <- NA
names(df1)[names(df1) == "X_BMI5"] <- "BMI_Num"

# Recode _BMI5CAT
df1$BMI_Cat <- factor(df1$`X_BMI5CAT`, levels = 1:4,
                         labels = c("Underweight", "Normal", "Overweight", "Obese"))

# Recode BPHIGH4
df1$BPHIGH4[df1$BPHIGH4 %in% c(7, 9)] <- NA
df1$BloodPressure <- factor(df1$BPHIGH4, levels = c(1, 2, 3, 4),
                      labels = c("Yes", "No", "Borderline", "Pregnancy"))

# Recode HLTHPLN1
df1$HLTHPLN1[df1$HLTHPLN1 %in% c(7, 9)] <- NA
df1$HealthCare <- factor(df1$HLTHPLN1, levels = c(1, 2), labels = c("Yes", "No"))

# Recode EXERANY2
df1$EXERANY2[df1$EXERANY2 %in% c(7, 9)] <- NA
df1$Exercise <- factor(df1$EXERANY2, levels = c(1, 2), labels = c("Yes", "No"))
```

<br><br>

#### 3) Handling Missing Values

**Filtering out rows with N/A**: In the last step of our dataset cleaning, we must ensure that our cleaned dataset doesn't have missing values in it. So we remove any rows within the dataset that have missing values in it, and export the dataset into a CSV file for any future use.

```{r}
# Remove rows with any NA values
df_clean <- na.omit(df1)  
nrow(df_clean)

#save cleaned files into csv
write.csv(df_clean, "~/Documents/GitHub/EDA_Project/data/cleaned_data.csv", row.names = FALSE)
```

<br><br>

### III. Data Visualization and Tendency Measurement

#### 1) Frequency Distribution of Heart Attack and Predictors

**Visualization**: In this section, we visualize the distribution of response variable **HeartAttack** and 9 predictors. We also measure the central tendency using mode, median, or mean depending on whether the variable is categorical, nominal, and numeric.

**Define Mode Functions for central tendency measurement**: We create the function get_mode(), a function we will later use for the central tendency measurement. Get_mode() takes in a vector form, which it then uses to create a table, tbl, of that vector, ultimately finding the value with the highest frequency in that table. For example, if a vector of [1,4,5,5] is imputed, we create a 2x2 table of the values, and find that 5 is the value with the highest frequency (as it is found twice in the array)

```{r}
df_clean <- read.csv("~/Documents/GitHub/EDA_Project/data/cleaned_data.csv")
```

```{r}
# Function to calculate mode
get_mode <- function(v) {
  tbl <- table(v)
  mode_val <- names(tbl)[which.max(tbl)]
  return(mode_val)
}
```

<br><br>

**(a)** Response Variable -- HeartAttack

```{r}
#table
table(df_clean$HeartAttack)
prop.table(table(df_clean$HeartAttack))

#Bar graph
ggplot(df_clean, aes(x = HeartAttack)) +
  geom_bar(fill = "#1a80bb", color = "black") +
  ggtitle("Bar Plot of HeartAttack Distribution") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

#Central Tendency -- Mode
cat("Head_Attack\n")
cat("Mode:", get_mode(df_clean$HeartAttack), "\n\n")
```

**Conclusion**: Based on the mode calculation, No is dominantly observed over Yes, meaning more people who filled out the questionnaire doesn’t have heart attack. However, there is still a sufficient amount of observations having heart attack, with an occurrence of 18,674, which is about 5.85% of the total sample size.
<br><br>

**(b)** Predictor -- Sex

```{r}
#table
table(df_clean$SEX)
prop.table(table(df_clean$SEX))

#Bar graph
ggplot(df_clean, aes(x = SEX)) +
  geom_bar(fill = "#1a80bb", color = "black") +
  ggtitle("Bar Plot of Sex Distribution") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

#Central Tendency -- Mode
cat("Sex\n")
cat("Mode:", get_mode(df_clean$SEX), "\n\n")
```

**Conclusion**:  Based on the mode calculation, female is dominantly observed over male (54.99% vs. 45.01%). This is something notable to consider when looking at other results from distributions and linear regression, as the subject's sex isn't evenly distributed, rather leaning more towards a higher count of female participants than of the male sex.
<br><br>

**(c)** Predictor -- Income

```{r}
#table
table(df_clean$INCOME)
prop.table(table(df_clean$INCOME))

#Bar graph
ggplot(df_clean, aes(x = INCOME)) +
  geom_bar(fill = "#1a80bb", color = "black") +
  ggtitle("Bar Plot of Income Distribution") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

#Central Tendency -- Mode and Median
cat("Income\n")
cat("Mode:", get_mode(df_clean$INCOME), "\n")

# Median (convert to numeric index and retrieve label)
income_numeric <- as.numeric(df_clean$INCOME)
income_levels <- levels(df_clean$INCOME)
income_median_label <- income_levels[median(income_numeric, na.rm = TRUE)]
cat("Median:", income_median_label, "\n")
```

**Conclusion**: The Income distribution is skewed to the left, with most subjects (or the mode) belonging to the income group of over 75 thousand dollars in income per year. When looking at the median that we calculated earlier, we can see that its results in 35-50k. This means that we have a lot more subjects that had a higher income value than other income groups.
<br><br>

**(d)** Predictor -- Race
```{r}
#table
table(df_clean$RACE)
prop.table(table(df_clean$RACE))

#Bar graph
ggplot(df_clean, aes(x = RACE)) +
  geom_bar(fill = "#1a80bb", color = "black") +
  ggtitle("Bar Plot of Race Distribution") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

#Central Tendency -- Mode
cat("Race\n")
cat("Mode:", get_mode(df_clean$RACE), "\n\n")
```

**Conclusion**: When looking at the predictor of Race, the distribution is highly imbalanced, with the mode of the data belonging to the race group of "White" (78.5% of the dataset). This distribution also tells us to be weary for the other parts of our study, as there isn't a proportionate distribution of all groups, which limits the results of our findings to other groups of the predictor.
<br><br>

**(e)** Predictor -- Age
```{r}
#table
table(df_clean$AGE)
prop.table(table(df_clean$AGE))

#Bar graph
ggplot(df_clean, aes(x = AGE)) +
  geom_bar(fill = "#1a80bb", color = "black") +
  ggtitle("Bar Plot of Age Distribution") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

#Central Tendency -- Mode and Median
cat("AGE\n")
cat("Mode:", get_mode(df_clean$AGE), "\n")
median_index <- median(as.numeric(df_clean$AGE), na.rm = TRUE)
median_label <- levels(df_clean$AGE)[median_index]
cat("Median:", median_label, "\n\n")
```

**Conclusion**: This Age distribution is skewed to the left, with more participants at older ages, and it has a median of 55-59. This makes our results much more comprehensive for ages across our range.
<br><br>

**(f)** Predictor -- BMI

We continue to plot and graph the distributions of these different predictors, but instead of simply calculataing mode and median, we add a calculation for mean of BMI, using a function from one of the libraries we installed and initialized earlier in the function - mean().

```{r}
#Bar graph
ggplot(df_clean, aes(x = BMI_Num)) +
  geom_bar(fill = "#1a80bb", color = "black") +
  ggtitle("Bar Plot of BMI Distribution") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

#Central Tendency -- Mode and Median and Mean
cat("BMI_Num\n")
cat("Mode:", get_mode(df_clean$BMI_Num), "\n")
cat("Median:", median(df_clean$BMI_Num, na.rm = TRUE), "\n")
cat("Mean:", mean(df_clean$BMI_Num, na.rm = TRUE), "\n\n")
```

**Conclusion**: We find that this distribution is skewed to the right, with a large tail that stretches towards the higher BMI values. This means that we have a very comprehensive distribution for the lower BMI values, but due to the large tail and few values at the higher end of range, our statistics such as mean (2820.969) and median (2712) are being skewed to the right. 
<br><br>

**(g)** Predictor -- Healthcare Coverage
```{r}
#table
table(df_clean$HealthCare)
prop.table(table(df_clean$HealthCare))

#Bar graph
ggplot(df_clean, aes(x = HealthCare)) +
  geom_bar(fill = "#1a80bb", color = "black") +
  ggtitle("Bar Plot of Healthcare Coverage Distribution") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

#Central Tendency -- Mode
cat("Healthcare_Coverage\n")
cat("Mode:", get_mode(df_clean$HealthCare), "\n\n")
```

**Conclusion**: Based on the mode calculation, Yes is dominantly observed over male (93.2% vs. 0.067%).This is another thing to take note of when we do further data analysis later on, in which the "No" cateogry is not fairly represented in this database, which can very well skew results.
<br><br>

#### 2) Correlation Analysis

In this section, for each predictor, we measure how the proportion of participants with heart attack changes across different categorical levels. This analysis provides an initial insight into the significance of each predictor; it also suggests the potential sign of coefficients in regression analysis on **HeartAttack**. 

```{r}
custom_colors <- c("No" = "#1a80bb", "Yes" = "#f2c45f")
```


**(a)** Heart Attack vs. Sex
```{r}
#Table
prop.table(table(df_clean$HeartAttack, df_clean$SEX), margin = 2)

#Bar graph
ggplot(df_clean, aes(x = SEX, fill = HeartAttack)) +
  geom_bar(position = "fill") +
  ylab("Proportion") +
  xlab("Sex") +
  labs(fill = "Heart Attack Status") +
  ggtitle("Proportion of Heart Attack by Sex") +
  scale_fill_manual(values = custom_colors) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

**Conclusion**: Based on the proportion and bar graph, the proportion of males getting heart attack is higher than the proportion of females (0.078 vs. 0.042), suggesting males having higher risks of getting heart attack than females. 
<br><br>

**(b)** Heart Attack vs. Income Level
```{r}

#Table
prop.table(table(df_clean$HeartAttack, df_clean$INCOME), margin = 2)

#Bar graph
ggplot(df_clean, aes(x = INCOME, fill = HeartAttack)) +
  geom_bar(position = "fill") +
  ylab("Proportion") +
  xlab("Income Level") +
  labs(fill = "Heart Attack Status") +
  ggtitle("Proportion of Heart Attack by Income Level") +
  scale_fill_manual(values = custom_colors) +
  scale_x_discrete(limits = c("<$10k", "$10-15k", "$15-20k", "$20-25k", "$25-35k", "$35-50k", "$50-75k", ">=75k")) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

**Conclusion**: Generally, the proportion of individuals having heart attack decreases as income level increases, suggesting a potential negative correlation between income level and odds of having heart attack. 
<br><br>

**(c)** Heart Attack vs. Race
```{r}
#Table
prop.table(table(df_clean$HeartAttack, df_clean$RACE), margin = 2)

#Bar graph
ggplot(df_clean, aes(x = RACE, fill = HeartAttack)) +
  geom_bar(position = "fill") +
  ylab("Proportion") +
  xlab("Race") +
  labs(fill = "Heart Attack Status") +
  ggtitle("Proportion of Heart Attack by Race") +
  scale_fill_manual(values = custom_colors) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

**Conclusion**: When looking at the bar plot we made, we do see a change in proportions of individuals having heart attack between the different categories of the Race predictor. Multiracial group is having the highest proportion of individuals with heart attack, and Hispanic group is having the lowest proportion of having heart attack.

**(d)** Heart Attack vs. Age
```{r}
#Table
prop.table(table(df_clean$HeartAttack, df_clean$AGE), margin = 2)

#Bar graph
ggplot(df_clean, aes(x = AGE, fill = HeartAttack)) +
  geom_bar(position = "fill") +
  ylab("Proportion") +
  xlab("Age") +
  labs(fill = "Heart Attack Status") +
  ggtitle("Proportion of Heart Attack by Age") +
  scale_fill_manual(values = custom_colors) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

**Conclusion**: Here we see a strong positive correlation between Age and the proportion of heart attacks. As the ages get higher and higher, so does the proportion of participants who noted that they did have a heart attack.
<br><br>

**(e)** Heart Attack vs. BMI Categories
```{r}
#Table
prop.table(table(df_clean$HeartAttack, df_clean$BMI_Cat), margin = 2)

#Bar graph
ggplot(df_clean, aes(x = BMI_Cat, fill = HeartAttack)) +
  geom_bar(position = "fill") +
  ylab("Proportion") +
  xlab("BMI") +
  labs(fill = "Heart Attack Status") +
  ggtitle("Proportion of Heart Attack by BMI Level") +
  scale_fill_manual(values = custom_colors) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

**Conclusion**: We do see a difference in proportion of heart attacks across the different categories of BMI. Obese group is having the highest proportion of having heart attack followed by underweight. Normal group has the lowest proportion of having heart attack.
<br><br>

**(f)** Heart Attack vs. Healthcare Coverage
```{r}
#Table
prop.table(table(df_clean$HeartAttack, df_clean$HealthCare), margin = 2)

#Bar graph
ggplot(df_clean, aes(x = HealthCare, fill = HeartAttack)) +
  geom_bar(position = "fill") +
  ylab("Proportion") +
  xlab("Healthcare Coverage") +
  labs(fill = "Heart Attack Status") +
  ggtitle("Proportion of Heart Attack by Healthcare Coverage") +
  scale_fill_manual(values = custom_colors) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

**Conclusion**: There does appear to be a correlation between Healthcare Coverage and the proportion of heart attacks. People with healthcare coverage is having a higher proportion of having heart attack.
<br><br>

### IV. Methodology

  In this project, **HeartAttack** is selected as the response variable. Because it is a binary variable describing whether or not the respondent has heart attack (1=yes, 0=no), it will be logit transformed into logit (P(HeartAttack)). Logistic regression will be used for predicting odds of having heart attack.

  In the bar graphs, for each predictor, we visualize proportion of individuals with heart attack across different categories. Based on this preliminary analysis, we have observed correlations between 5 selected predictors with response variable **HeartAttack**. Significant predictors include **SEX**, **Income**, **AGE**,**Race**, **Health Coverage**. Proportions of individuals with heart attack vary across different categorical levels, and it is observed in these predictors.  

  Specifically, we set **BMI** as the predictor in the main model. The significance of the predictor’s relationship with heart attack will be assessed using individual Z-tests. Other categorical factors will add as additive predictors in the extended model, which include **SEX**, **Income**, **Race**, **Age**, and **Health Coverage** . Because they are categorical variables, we will analyze how the odds of having heart attack change when the category changes within each variable. Their overall contribution will first be evaluated using partial $\chi^2$ tests, and differences among levels of categorical predictors will be further examined through individual Z-tests. Only variables showing significant differences in heart attack odds across levels will be retained.
  
  Based on the significance results from both individual Z-tests and partial $\chi^2$ tests, the final extended model will be constructed. To ensure robustness, the final model will be assessed for influential data points using Cook’s distance and outlier tests for regression outliers. Multicollinearity between multiple predictors in the extensive models will be evaluated based on **Variance Inflation factor (VIF)**. The final model’s performance will be validated through goodness-of-fit measures: error rate test, which assess how well the model predicts the actual odds of heart attack.
<br><br>

### V. Result and Conclusion

#### 1) Main Model

```{r}
df_clean$HeartAttack <- as.factor(df_clean$HeartAttack)
df_clean$SEX <- as.factor(df_clean$SEX)
df_clean$RACE <- as.factor(df_clean$RACE)
df_clean$INCOME <- as.factor(df_clean$INCOME)
df_clean$HealthCare <- as.factor(df_clean$HealthCare)
```


**(a)** Heart Attack vs. BMI

```{r}
#Full model
df_clean$HeartAttack <- ifelse(df_clean$HeartAttack == "Yes", 1, 0)
glm_main <- glm(HeartAttack ~ BMI_Num, data = df_clean, family = binomial(logit))
summary(glm_main)
```

$H_0$: $\hat{\beta}_{BMI} = 0$

$H_a$: $\hat{\beta}_{BMI} \neq 0$

P-value: < 2.2e-16

**Conclusion**: 

- Individual Z test: at the $\alpha = 0.05$ level of significance, we reject $H_0$. $\hat{\beta}_{BMI}$ is significantly greater than 0, and there is a significant positive association between Body Mass Index (BMI) and the odds of having heart attack

- Slope interpretation: $\hat{\beta}_{BMI} = 2.196e-04$. An one unit ($kg/m^2$) increase in BMI increases the odds of having heart attack by a multiplicative factor of $e^{0.0002196} = 1.00022$. A one unit increase in BMI increases the odds of having heart attack by 0.022%.
<br><br>

#### 2) Extended Model: Heart Attack vs. BMI + Demographic predictors

While BMI shows a significant relationship with odds of having heart attack. Other factors like demographic predictors are also connected to heart attack. Specifically, sex, age, income level, insurance coverage, and race are included in the extended model based on the main model with BMI. Their relationship with odds of having heart attack is tested. 
<br><br>

**(a)** Overall $\chi^2$ Test
<br><br>
**Purpose**: overall $\chi^2$ test is firstly performed to test if at least on predictor in the model is significant and if the model is useful for more detailed analysis.
```{r}
glm_extend <- glm(HeartAttack ~ BMI_Num + SEX + AGE_Num + RACE + INCOME + HealthCare, data = df_clean, family = binomial(logit))
glm_null <- glm(HeartAttack ~ 1, data = df_clean, family = binomial(logit))
anova(glm_null, glm_extend, test = "Chisq")
```

$H_0$: All slopes = 0

$H_a$: At least one $\beta_j \neq 0$

P-value: < 2.2e-16

**Conclusion**: The p-value is < 2.2e-16, which is less than the significance level of 0.05. Thus, we reject the null hypothesis, and there is at least one significant predictor for odds of having heart attack in the logistic model. 
<br><br>

**(b)** Partial $\chi^2$ Test
<br><br>
**Purpose**: From the overall $X^2$ test, at least one predictor is significant in predicting odds of having heart attack. In the anova table, a more detailed analysis is conducted to test which independent variables are specifically related with odds of having heart attack. Dummy variables for each predictor is combined together.

```{r}
glm_extend <- glm(HeartAttack ~ BMI_Num + SEX + AGE_Num + RACE + INCOME + HealthCare, data = df_clean, family = binomial(logit))

Anova(glm_extend, type="III")
```

**Conclusion**: From the anova table, all the independent variables show significant relationship with odds of having heart attack. Sex, age, race, and income level have p-values < 2.2e-16. Healthcare coverage has a p-value is 0.0004477. 
<br><br>

**(c)** Individual Z Test
<br><br>
**Purpose**: From the partial $\chi^2$ Test, all the independent variables are significantly related with odds of having heart attack. An individual Z Test is further preformed to check differences in odds of having heart attack within levels of each independent variable.

```{r}
#Baseline Code for Dummy variables
contrasts(df_clean$SEX)
contrasts(df_clean$RACE)
contrasts(df_clean$INCOME)
contrasts(df_clean$HealthCare)
```

```{r}
#Individual Z test
summary(glm_extend)
```

**Conclusion**:

1) **Sex**: Men have higher odds of having heart attack.

- Slope interpretation: $\hat{\beta}_{Sex} = 0.9222827$. When keeping every other conditions the same, male have $e^{0.9222827} = 2.515$ times higher odds of having heart attack compared to females.
<br><br>

2) **Age**: Odds of having heart attack increases as age increases.

- Individual Z test: p-value is < 2e-16

- Slope interpretation: $\hat{\beta}_{Age} = 0.06015$. In this model, when keeping every other conditions the same, an one year increase in age increases the odds of having heart attack by a multiplicative factor of $e^{0.06015} = 1.06343$, it increases the odds by 6.343%.
<br><br>

3) **Income Level**: Odds of having heart attack decreases when income level increases. 

- **$10-15k**: when comparing to the baseline group (*Less than $10,000*), *$10-15k* income level has $e^{-0.1087} = 0.8970$ times lower odds of having heart attack, it has a lower odds by 10.3%.

- **$15-20k**: when comparing to the baseline group (*Less than $10,000*), *$15-20k* income level has $e^{-0.2909} = 0.7476$ times lower odds of having heart attack, it has a lower odds by 25.24%.

- **$20-25k**: when comparing to the baseline group (*Less than $10,0000*), *$20-25k* income level has $e^{-0.5422} = 0.5815$ times lower odds of having heart attack, it has a lower odds by 41.85%.

- **$25-35k**: when comparing to the baseline group (*Less than $10,000*), *$25-35k* income level has $e^{-0.7404} = 0.4769$ times lower odds of having heart attack, it has a lower odds by 52.31%.

- **$35-50k**: when comparing to the baseline group (*Less than $10,000*), *$35-50k* income level has $e^{-0.9335} = 0.3932$ times lower odds of having heart attack, it has a lower odds by 60.68%.

- **$50-75k**: when comparing to the baseline group (*Less than $10,000*), *$50-75k* income level has $e^{-1.141} = 0.3195$ times lower odds of having heart attack, it has a lower odds by 68.05%.
<br><br>

4) **Race**: Hispanic people has lowest odds of having heart attack. Within defined race groups, multiracial people has highest odds of having heart attack.

- **Hispanic**: when comparing to the baseline group (*Black*), black people has $e^{-0.1246} = 0.8828$ times lower odds of having heart attack, it has lowered odds by 11.72%.

- **Multiracial**: when comparing to the baseline group (*Black*), people from other race groups has $e^{0.4913} = 1.634$ times higher odds of having heart attack, it has a higher odds by 63.4%.

- **Other**: when comparing to the baseline group (*Black*), multiracial people has $e^{0.1987} = 1.220$ times higher odds of having heart attack, it has a higher odds by 22.0%.

- **White**: when comparing to the baseline group (*Black*), Hispanic people has $e^{0.1727} = 1.189$ times higher odds of having heart attack, it has a higher odds by 18.9%.
<br><br>

5) **HealthCare Coverage**: Having healthcare coverage have higher odds of having heart attack.

- Slope interpretation: $\hat{\beta}_{Sex} = 0.1146$. When keeping every other conditions the same, people with healthcare coverage have $e^{0.1146} = 1.121$ times higher odds of having heart attack compared to people without healthcare coverage. Having healthcare coverage increases odds of having heart attack by 12.1%.
<br><br>

**(c)** Plot Logistic Regression
<br><br>

1) Ordinal & Numerical Predictors
```{r}
# --- Bar plot for categorical predictor (INCOME) ---
plot_income_bar <- function(model) {
  emm <- emmeans(model, ~ INCOME, type = "response")
  emm_df <- as.data.frame(emm)
  
  ggplot(emm_df, aes(x = INCOME, y = prob)) +
    geom_col(fill = "#1a80bb") +
    geom_errorbar(aes(ymin = asymp.LCL, ymax = asymp.UCL), width = 0.2) +
    scale_x_discrete(limits = c("<$10k", "$10-15k", "$15-20k", "$20-25k",
                                "$25-35k", "$35-50k", "$50-75k", ">=75k")) +
    ylab("Predicted Probability of Heart Attack") +
    xlab("Income Level") +
    ggtitle("Predicted Risk by Income Level") +
    theme_minimal() +
    theme(axis.text.x = element_text(angle = 45, hjust = 1))
}

# --- Line plot for numeric predictor ---
plot_numeric_line <- function(model, term, x_label) {
  pred <- ggpredict(model, terms = term)
  
  ggplot(pred, aes(x = x, y = predicted)) +
    geom_line(color = "blue", size = 1) +
    geom_ribbon(aes(ymin = conf.low, ymax = conf.high), alpha = 0.2) +
    ylab("Predicted Probability of Heart Attack") +
    xlab(x_label) +
    ggtitle(paste("Predicted Risk by", x_label)) +
    theme_minimal()
}

# --- Generate plots ---
plot_income  <- plot_income_bar(glm_extend)
plot_age     <- plot_numeric_line(glm_extend, "AGE_Num", "Age")
plot_bmi     <- plot_numeric_line(glm_extend, "BMI_Num", "BMI")

# --- View plots ---
print(plot_income)
print(plot_age)
print(plot_bmi)
```
<br><br>

2) Categorical Predictors
```{r}
plot_predicted_probs <- function(varname, model) {
  emm <- emmeans(model, as.formula(paste("~", varname)), type = "response")
  emm_df <- as.data.frame(emm)

  p <- ggplot(emm_df, aes_string(x = varname, y = "prob")) +
    geom_col(fill = "skyblue") +
    geom_errorbar(aes(ymin = asymp.LCL, ymax = asymp.UCL), width = 0.2) +
    ylab("Predicted Probability of Heart Attack") +
    xlab(varname) +
    ggtitle(paste("Predicted Risk by", varname)) +
    theme_minimal()

  # Follow your example: set axis order via scale_x_discrete (plot-only)
  if (varname == "INCOME") {
    p <- p +
      scale_x_discrete(limits = c("<$10k", "$10-15k", "$15-20k", "$20-25k",
                                  "$25-35k", "$35-50k", "$50-75k", ">=75k")) +
      theme(axis.text.x = element_text(angle = 45, hjust = 1))
  }

  p
}

# Use with your fitted model glm_extend
plot_sex        <- plot_predicted_probs("SEX", glm_extend)
plot_race       <- plot_predicted_probs("RACE", glm_extend)
plot_income     <- plot_predicted_probs("INCOME", glm_extend)
plot_healthcare <- plot_predicted_probs("HealthCare", glm_extend)

print(plot_sex)
print(plot_race)
print(plot_income)
print(plot_healthcare)
```
<br><br>

**(d)** Multicollinearity for Extended Model
```{r}
vif(glm_extend)
```

**Conclusion**: Based on the variance inflation factor, no multicollinearity is observed between predictors. All predictors have GVIF around 1, suggesting a very low multicollinearity, and each predictor contributes unique information to the model.
<br><br>

#### 3) Extended Model: Heart Attack vs. BMI + Demographic predictors + Interaction term
Partial $\chi^2$ test is conducted to test if each interactive term is specifically related with odds of having heart attack Individual levels within each qualitative variable is combined and tested together.  
```{r}
glm_full <- glm(HeartAttack ~ BMI_Num + SEX + AGE_Num + RACE + INCOME + HealthCare + Exercise + BMI_Num:SEX + BMI_Num:AGE_Num + BMI_Num:RACE + BMI_Num:INCOME + BMI_Num:HealthCare, data = df_clean, family = binomial(logit))

Anova(glm_full, type = "III")

glm_full_revised <- glm(HeartAttack ~ BMI_Num + SEX + AGE_Num + RACE + INCOME + HealthCare + Exercise + BMI_Num:AGE_Num + BMI_Num:RACE, data = df_clean, family = binomial(logit))
```

**Conclusion**: From the anova table, BMI shows significant interaction effects with race, suggesting that the impact of BMI on heart attack risk is not uniform across race subgroups. Specifically, the relationship between BMI and the odds of having heart attack is moderated by race. Therefore, it cannot be interpreted independently of race factor.
<br><br>

$$
\ln\left(\frac{P(\text{Heart Attack} = 1)}{1 - P(\text{Heart Attack} = 1)}\right) =
\hat{\beta}_0 +
\hat{\beta}_1 \cdot \texttt{BMI} +
\hat{\beta}_2 \cdot \texttt{Sex} +
\hat{\beta}_3 \cdot \texttt{Age} +
\hat{\beta}_4 \cdot \texttt{Race} +
\hat{\beta}_5 \cdot \texttt{Income} +
\hat{\beta}_6 \cdot \texttt{Healthcare Coverage} +
\hat{\beta}_8 \cdot (\texttt{BMI} \times \texttt{Race})
$$

#### 4) Goodness of Fit Test

Purpose: after deriving the final model that is the best at predicting odds of having heart attack, error rate is calculated. It aims to assess how well the model predicts the actual odds of heart attack. 

**(a)** Error Rate
```{r}
glm.probs <- predict(glm_full_revised, type = "response")
dim(df_clean)
glm.pred<-rep(0, length(glm.probs))    #creating empty vector
glm.pred[glm.probs > 0.5]<-1      #assign >0.5 predicted_Y = 1; if < 0.5 predicted_Y = 0
table(glm.pred, df_clean$HeartAttack)

#error rate
error <- (18412+11)/315938
error
```

**Conclusion**: The error rate is `r error`, which is around 0.05. Thus, the logistic model is good for predicting odds of having heart attack 
<br><br>
