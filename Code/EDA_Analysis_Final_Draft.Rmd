---
title: "EDA Notebook Analysis"
output: html_document
date: "2025-07-17"
Author: Yumeng Tan, Sherelle Li, Rom Zuckerman
---
### Heart Attack Exploratory Data Analysis

**Team Members**: Yumeng Tan, Sherelle Li, Rom Zuckerman

### I. Introduction

#### 1) Introducing the Dataset

  For this project, we work with data from the **2015 Behavioral Risk Factor Surveillance System (BRFSS)** -- a nationwide health survey run each year by the **Centers for Disease Control and Prevention (CDC)** in partnership with U.S. states and territories. The survey is conducted through telephone interviews, both land-line and cellular, reaching adults aged 18 and older living in community settings.  

  The BRFSS was designed to track health-related risk behaviors, chronic conditions, and use of preventive care across the U.S. In 2015, it collected information from 441,456 individuals, and the result spanned over all 50 states, the District of Columbia, Puerto Rico, and Guam. Having a large and representative sample sizes, the dataset give us a rich and reliable snapshot of health behaviors nationwide. The dataset also include 330 columns, which allows us to have a wide range of variables to explore and test on. 
  
  Beside having a large sample sizes, **2015 BRFSS** dataset also have other practical and methodological reasons that matter for our exploration. Firstly, the dataset is weighted so its findings reflect state-level populations—making it a trusted source for public health planning, policy-making, and resource allocation. Secondly, more recent datasets have **gaps in state coverage** -- for example, the 2023 survey omits large states such as Pennsylvania and Kentucky—which could make national estimates less reliable. Thus, compare to other dataset, **2015 BRFSS** dataset provides a more representative and comprehensive insight into the U.S populations, providing a reliable data for research purposes. 
<br><br>

#### 2) Research Interest

  The original dataset has 330 columns, making it hard to track specific variables that we are going to use in this research. Thus, we subset the dataset by only selecting variables related to the research in our final dataset. 
  
  Our main outcome of interest is **heart attack** (`CVDINFR4`). This choice is deliberate: heart attacks are urgent, affecting 17.9 millions of lives each year. Thus, it demands immediate medical attention ([NIH](https://www.nhlbi.nih.gov/health/heart-attack)). However, heart attacks can occur even without a prior coronary heart disease diagnosis ([ClevelandClinic](https://my.clevelandclinic.org/health/diseases/16818-heart-attack-myocardial-infarction)). As a result, identifying predictors is necessary for preventing heart attack, and it is our main goal of this study.
  
  Based on preliminary research, **Body Mass Index (BMI)** is potentially related to heart attack and is chosen as the main predictor of heart attack risks in this study. According to studies, extra fat increases inflammation, insulin resistance, and arterial damage discussing groups that may be more vulnerable or underrepresented ([NIH](https://pmc.ncbi.nlm.nih.gov/articles/PMC8449192/). Moreover, BMI is the primary diagnosing metrics for obesity, a disease that has impacts 41.9% of U.S. adults ([CDC](https://www.cdc.gov/obesity/adult-obesity-facts/index.html)). Given the wide impacts of obesity on U.S adults, exploring correlation between BMI and heart attack risks can have significant implication to a wide range of U.S populations. As a result, we use **Body Mass Index (BMI)** as the main predictor for heart attack risks in this study.
  
  While BMI is a potential predictor of heart attack, its relationship with heart attack risks may be modulated and confounded by other demographic variables. Thus, in this study, we also explore the interaction between four demographic factors and BMI, and we controlled these covariates by including them in the model. The demographic variables include: **Sex**, **Race**, **Age**, and **Income**. 
  
  In our regression model, we use **Body Mass Index** as our main predictor, and we include **Sex**, **Race**, **Age**, and **Income** as covariates in the model. Based on our selection of predictors, we subset our original 2015 BRFSS dataset to only include these variables in our final dataset. With that in mind, let’s look at the specific variables that will guide our exploration.  

- **CVDINFR4**: Whether the respondent has ever been told they had a heart attack (myocardial infarction).  
  - 1 = Yes - 2 = No - 7 = Don’t know - 9 = Refused  

- **SEX**: Biological sex of the respondent.  
  - 1 = Male - 2 = Female  

- **INCOME2**: Annual household income from all sources, in categorical brackets.  
  - 1–8 = Ranges from < $10,000 to ≥ $75,000 - 77 = Don’t know - 99 = Refused  

- **X_RACEGR3**: Race group (recoded into 3 categories).  
  - 1 = White only - 2 = Black only - 3 = Other or multiracial  

- **X_AGEG5YR**: Age group in 5-year intervals.  
  - 1 = 18–24 - 2 = 25–29 - ... - 13 = 80+  

- **X_BMI5**: Body Mass Index (BMI), calculated as BMI × 100.  
  - Continuous variable: Divide by 100 to get actual BMI  

- **X_BMI5CAT**: BMI category based on X_BMI5.  
  - 1 = Underweight - 2 = Normal weight - 3 = Overweight - 4 = Obese  

  Taken together, these variables give us a comprehensive prediction on heart attack risks. The next step in our exploration will be preparing and transforming the data so we can uncover these relationships in a clear, systematic way.
<br><br>

### II. Dataset Manipulation

#### 1) Loading dataset and packages

1. **Install and load packages**: We set up the environment and install the packages necessary for our data analysis below. In the code below, we load all the installed packages to make the functions within them available to use in our script.

```{r}
# Load libraries
library(ggplot2)
library(car)
library(carData)
library(ResourceSelection)
library(pROC)
library(dplyr)
library(emmeans)
library(ggeffects)
```
<br><br>

2. **Loading Dataset**: We first load our original dataset **2015.csv** into R Studio as data frame **df**, and we shows the first 6 observations of the dataset usnig the function head(). 

```{r}
#Load original dataset
df <- read.csv("~/Documents/GitHub/EDA_Project/data/2015.csv")
head(df)
```
<br><br>

3. **Selecting relevant variables**: The original dataset **df** has 330 variables. To have a more effective and concise dataset, we subset the dataset to include only include variables that will be used for future analysis. These include response variable -- heart attack(`CVDINFR4`), and predictors -- sex(`SEX`), income level(`INCOME2`), race(`X_RACEGR3`), age(`X_AGE80` for numeric; `X_AGEG5YR` for categorical), and BMI(`X_BMI5` for numeric; `X_BMI5CAT` for categorical). We subset the dataset and import the new dataset as data frame **df1**.

```{r}
#Select relevant predictors and dependent variable
df1 <- df[, c("CVDINFR4", "SEX", "INCOME2", "X_RACEGR3", "X_AGEG5YR", "X_AGE80", "X_BMI5",
              "X_BMI5CAT")]
```
<br><br>

#### 2) Factoring and Renaming Variables 

After selecting response variable and main predictors, we redefine our variables in three setps: factor variables, rename variables, and detect NA in the dataset.

  **Factor variables**: In the original dataset, all variables are coded as numbers, including categorical values. Thus, we first factor all the predictors by changing numbers into their corresponding categorical labels. We do this by using factor() functions.
  
  **Rename variables**: We also rename variables by storing factored variables into a clearer name.
  
  **Detect NA**: For NA values, they are encoded as specific numbers for each predictor. The specific values representing NA are written in the 2015 codebook report on CDC website. We look up for numbers that represent NA for each variable, and we recode these numbers into "NA" using factor() functions.
<br><br>

**(a)** Response Variable -- HeartAttack

Our response variable Heart Attack is named as `CVDINFR4` in the original dataset and include 4 categories: 1 = No, 2 = Yes, 7 = Don't Know, 9 = Refused. We first factor the variable to replace numeric values with categorical labels by using function factor(). Specifically, we relabel 1 and 2 into No and Yes, and we relabel 7 and 9 into NA. Then we store the relabeled variable into a new variable `HeartAttack`.

```{r}
# Recode CVDINFR4
df1$CVDINFR4[df1$CVDINFR4 %in% c(7, 9)] <- NA
df1$HeartAttack <- factor(df1$HeartAttack, levels = c(1, 2), labels = c("No", "Yes"))
```
<br><br>

**(b)** Main Predictor -- Body Mass Index

Our main predictor Body Mass Index (BMI) is named as `X_BMI5` in the original dataset and is numeric discrete variable. We first factor the variable using function factor(). Specifically, we relabel 9999 into NA, because it represents "Don’t know/Refused/Missing". Then we store the relabeled variable into a new variable `BMI_Num`. Beyond factoring and renaming the variable, we also divide the variable with 100. In the original dataset, BMI is represented by BMI * 100%, therefore, to show the actual BMI value, we divide the variable by 100. 

```{r}
# Recode _BMI5 
df1$`X_BMI5`[df1$`X_BMI5` == 9999] <- NA
names(df1)[names(df1) == "X_BMI5"] <- "BMI_Num"
df1$BMI_Num <- df1$BMI_Num / 100
```
<br><br>

While BMI as a numeric variable is used in the regression model, BMI as categorical variable with 4 categories is used in the EDA analysis and bar graphs. It is named as `X_BMI5CAT` in the original dataset and include 4 categories: 1 = Underweight, 2 = Normal, 3 = Overweight, 4 = Obese. We factor the variable to replace numeric values with categorical labels by using function factor(). Then we store the relabeled variable into a new variable `BMI_Cat`.

```{r}
# Recode _BMI5CAT
df1$BMI_Cat <- factor(df1$`X_BMI5CAT`, levels = 1:4,
                         labels = c("Underweight", "Normal", "Overweight", "Obese"))
```
<br><br>

**(c)** Demographic Predictor -- Sex

The first demographic predictor sex is named as `SEX` in the original dataset and include 2 categories: 1 = Male, 2 = Female. We factor the variable to replace numeric values with categorical labels by using function factor(). Then we store the relabeled variable into a new variable `SEX`.

```{r}
# Recode SEX
df1$SEX <- factor(df1$SEX, levels = c(1, 2), labels = c("Male", "Female"))
```
<br><br>

**(d)** Demographic Predictor -- Income

The second demographic predictor income is named as `INCOME2` in the original dataset and include 9 categories: 1 = <$10k, 2 = $10-15k, 3 = $15-20k, 4 = $20-25k, 5 = $25-35k, 6 = $35-50k, 7 = $50-75k, 8 = $>=75k, 77 or 99 = Don’t know/Not sure/Missing. We factor the variable to replace numeric values with categorical labels by using function factor(). We also we relabel 77 and 99 into NA. Then we store the relabeled variable into a new variable `INCOME`.

```{r}
# Recode INCOME2
df1$INCOME2[df1$INCOME2 %in% c(77, 99)] <- NA
df1$INCOME <- factor(df1$INCOME2, levels = c(1:8),
                      labels = c("<$10k", "$10-15k", "$15-20k", "$20-25k", "$25-35k",
                                 "$35-50k", "$50-75k", ">=75k"))
```
<br><br>

**(e)** Demographic Predictor -- Race

The third demographic predictor race is named as `X_RACEGR3` in the original dataset and include 6 categories: 1 = White, 2 = Black, 3 = Other, 4 = Multiracial, 5 = Hispanic, 9 = Don’t know/Not sure/Missing. We factor the variable to replace numeric values with categorical labels by using function factor(). We also we relabel 9 into NA. Then we store the relabeled variable into a new variable `RACE`.

```{r}
# Recode _RACEGR3 as factor with appropriate labels
df1$`X_RACEGR3`[df1$`X_RACEGR3` == 9] <- NA
df1$RACE <- factor(df1$`X_RACEGR3`,
                         levels = c(1:5),
                         labels = c("White", "Black", "Other",
                                    "Multiracial", "Hispanic"))
```
<br><br>

**(f)** Demographic Predictor -- Age

The fourth demographic predictor age is named as `X_AGE80` in the original dataset and is numeric discrete variable. We store the relabeled variable into a new variable `AGE_Num`.

```{r}
# Recode _AGE80 
names(df1)[names(df1) == "X_AGE80"] <- "AGE_Num"
```
<br><br>

While age as a numeric variable is used in the regression model, age as categorical variable with 13 categories is used in the EDA analysis and bar graphs. It is named as `X_AGEG5YR` in the original dataset and include 13 categories. We factor the variable to replace numeric values with categorical labels by using function factor(). Then we store the relabeled variable into a new variable `AGE`.

```{r}
# Recode _AGEG5YR
df1$AGE <- factor(df1$`X_AGEG5YR`, levels = 1:13,
                         labels = c("18–24", "25–29", "30–34", "35–39", "40–44", "45–49",
                                    "50–54", "55–59", "60–64", "65–69", "70–74", "75–79", "80+"))
```
<br><br>

#### 3) Handling Missing Values

In the previous step, we rename and factor relevant variables, we also detect and define NA for each variable. The next step is to remove any rows with NA values. We remove any rows within the dataset that have missing values using na.omit() functions. We then store the dataset into a new dataset called **df_clean**, and we export the dataset into a CSV file for future use using write.csv() functions.

```{r}
# Remove rows with any NA values
df_clean <- na.omit(df1)  

#save cleaned files into csv
write.csv(df_clean, "~/Documents/GitHub/EDA_Project/data/cleaned_data.csv", row.names = FALSE)
```
<br><br>

#### 4) Importing Cleanded Dataset

The final cleanded dataset is imported into R for future research use using read.csv(). The dataset is imported as a dataframe named df_clean.

```{r}
df_clean <- read.csv("~/Documents/GitHub/EDA_Project/data/cleaned_data.csv")
```


### III. Data Visualization and Tendency Measurement

#### 1) Frequency Distribution of Heart Attack and Predictors

**Visualization**: After getting a cleaned dataset, we visualize the distribution of response variable **HeartAttack** and 5 predictors. We also measure the central tendency using mode, median, or mean depending on whether the variable is categorical, nominal, and numeric. For distribution statistics, we first calculated the frequency of observations within each category using table(), and we also convert frequency to proportion using prop.table(). For visualizing distribution, we use bar graphs to plot the proportion of observations within each category using ggplot().

**Define Mode Functions for central tendency measurement**: We create the function get_mode(), a function we will later use for the central tendency measurement. Get_mode() takes in a vector form, which it then uses to create a table of that vector, ultimately finding the value with the highest frequency in that table. 

```{r}
# Function to calculate mode
get_mode <- function(v) {
  tbl <- table(v)
  mode_val <- names(tbl)[which.max(tbl)]
  return(mode_val)
}
```
<br><br>

**(a)** Response Variable -- HeartAttack

Distribution is calculated and visualized as described above. For central tendency measurement, we calculate mode of the variable since it is categorical.

```{r}
#table
table(df_clean$HeartAttack)
prop.table(table(df_clean$HeartAttack))

#Bar graph
ggplot(df_clean, aes(x = HeartAttack)) +
  geom_bar(fill = "#1a80bb", color = "black") +
  ggtitle("Bar Plot of HeartAttack Distribution") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

#Central Tendency -- Mode
cat("Head_Attack\n")
cat("Mode:", get_mode(df_clean$HeartAttack), "\n\n")
```

**Interpretation**: Based on the mode calculation, No is dominantly observed over Yes, meaning more people who filled out the questionnaire doesn’t have heart attack. However, there is still a sufficient amount of observations having heart attack, with an occurrence of 18,674, which is about 5.85% of the total sample size.
<br><br>

**(b)** Predictor -- BMI

For distribution statistics and visualizing distribution, we use categorical variable -- BMI_Cat. When using numeric version, the proportion is calculated for each numeric value. The resulting proportion may be hard to see, and the variation may not be significant. Contrarily, categorical version give us a better understanding of how distribution varies across main categorical levels. For central tendency measurement, we return to BMI_Num to measure more detailed statistic, and we calculate mode, median, and mean of the variable.

```{r}
#table
table(df_clean$BMI_Cat)
prop.table(table(df_clean$BMI_Cat))

#Bar graph
ggplot(df_clean, aes(x = BMI_Cat)) +
  geom_bar(fill = "#1a80bb", color = "black") +
  ggtitle("Bar Plot of BMI Distribution") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

#Central Tendency -- Mode and Median and Mean
cat("BMI_Num\n")
cat("Mode:", get_mode(df_clean$BMI_Num), "\n")
cat("Median:", median(df_clean$BMI_Num, na.rm = TRUE), "\n")
cat("Mean:", mean(df_clean$BMI_Num, na.rm = TRUE), "\n\n")
```

**Interpretation**: We find that this distribution is skewed to the right, with a large tail that stretches towards the higher BMI values. This means that we have a very comprehensive distribution for the lower BMI values, but due to the large tail and few values at the higher end of range, our statistics such as mean (2820.969) and median (2712) are being skewed to the right. 
<br><br>

**(c)** Predictor -- Sex

Distribution is calculated and visualized as described above. For central tendency measurement, we calculate mode of the variable since it is categorical.

```{r}
#table
table(df_clean$SEX)
prop.table(table(df_clean$SEX))

#Bar graph
ggplot(df_clean, aes(x = SEX)) +
  geom_bar(fill = "#1a80bb", color = "black") +
  ggtitle("Bar Plot of Sex Distribution") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

#Central Tendency -- Mode
cat("Sex\n")
cat("Mode:", get_mode(df_clean$SEX), "\n\n")
```

**Interpretation**:  Based on the mode calculation, female is dominantly observed over male (54.99% vs. 45.01%). This is something notable to consider when looking at other results from distributions and linear regression, as the subject's sex isn't evenly distributed, rather leaning more towards a higher count of female participants than of the male sex.
<br><br>

**(d)** Predictor -- Income

Distribution is calculated and visualized as described above. For central tendency measurement, we calculate mode of the variable since it is categorical. 

```{r}
#table
table(df_clean$INCOME)
prop.table(table(df_clean$INCOME))

#Bar graph
ggplot(df_clean, aes(x = INCOME)) +
  geom_bar(fill = "#1a80bb", color = "black") +
  ggtitle("Bar Plot of Income Distribution") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

#Central Tendency -- Mode
cat("Income\n")
cat("Mode:", get_mode(df_clean$INCOME), "\n")
```

**Interpretation**: The Income distribution is skewed to the left, with most subjects (or the mode) belonging to the income group of over 75 thousand dollars in income per year. This means that we have a lot more subjects that had a higher income value than other income groups.
<br><br>

**(e)** Predictor -- Race

Distribution is calculated and visualized as described above. For central tendency measurement, we calculate mode of the variable since it is categorical. 

```{r}
#table
table(df_clean$RACE)
prop.table(table(df_clean$RACE))

#Bar graph
ggplot(df_clean, aes(x = RACE)) +
  geom_bar(fill = "#1a80bb", color = "black") +
  ggtitle("Bar Plot of Race Distribution") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

#Central Tendency -- Mode
cat("Race\n")
cat("Mode:", get_mode(df_clean$RACE), "\n\n")
```

**Interpretation**: When looking at the predictor of Race, the distribution is highly imbalanced, with the mode of the data belonging to the race group of "White" (78.5% of the dataset). This distribution also tells us to be weary for the other parts of our study, as there isn't a proportionate distribution of all groups, which limits the results of our findings to other groups of the predictor.
<br><br>

**(f)** Predictor -- Age

For distribution statistics and visualizing distribution, we use categorical variable -- AGE. When using numeric version, the proportion is calculated for each numeric value. The resulting proportion may be hard to see, and the variation may not be significant. Contrarily, categorical version give us a better understanding of how distribution varies across main categorical levels. For central tendency measurement, we return to AGE_Num to measure more detailed statistic, and we calculate mode, median, and mean of the variable.

```{r}
#table
table(df_clean$AGE)
prop.table(table(df_clean$AGE))

#Bar graph
ggplot(df_clean, aes(x = AGE)) +
  geom_bar(fill = "#1a80bb", color = "black") +
  ggtitle("Bar Plot of Age Distribution") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

#Central Tendency -- Mode and Median
cat("AGE_Num\n")
cat("Mode:", get_mode(df_clean$AGE_Num), "\n")
cat("Median:", median(df_clean$AGE_Num, na.rm = TRUE), "\n")
cat("Mean:", mean(df_clean$AGE_Num, na.rm = TRUE), "\n\n")
```

**Interpretation**: This Age distribution is skewed to the left, with more participants at older ages, and it has a median of 55-59. This makes our results much more comprehensive for ages across our range.
<br><br>

#### 2) Correlation Analysis

In this section, for each predictor, we measure how the proportion of participants with heart attack changes across different categorical levels. This analysis provides an initial insight into the significance of each predictor; it also suggests the potential sign of coefficients in regression analysis on **HeartAttack**. For distribution statistics of heart attack across each predictor, we first calculated the proportion of individuals with heart attack within each category using prop.table(). For visualizing distribution of heart attack across each predictor, we use bar graphs to plot the proportion of people with heart attack within each category using ggplot(). 

We first define the main theme color for the future bar graphs
```{r}
custom_colors <- c("No" = "#1a80bb", "Yes" = "#f2c45f")
```
<br><br>

**(a)** Heart Attack vs. BMI Categories

For distribution statistics and visualizing distribution of heart attack across BMI levels, we use categorical variable -- BMI_Cat. When using numeric version, the proportion is calculated for each numeric value. The resulting proportion may be hard to see, and the variation may not be significant. Contrarily, categorical version give us a better understanding of how distribution varies across main categorical levels.

```{r}
#Table
prop.table(table(df_clean$HeartAttack, df_clean$BMI_Cat), margin = 2)

#Bar graph
ggplot(df_clean, aes(x = BMI_Cat, fill = HeartAttack)) +
  geom_bar(position = "fill") +
  ylab("Proportion") +
  xlab("BMI Level") +
  labs(fill = "Heart Attack Status") +
  scale_x_discrete(
    limits = c("Normal", "Overweight", "Obese"),
    labels = c(
      "Normal"      = "Normal Weight (18.5–24.9)",
      "Obese"       = "Obese (≥ 30.0)",
      "Overweight"  = "Overweight (25.0–29.9)"
    ),
    drop = TRUE
  ) +
  ggtitle("Proportion of Heart Attack by BMI Levels") +
  scale_fill_manual(values = custom_colors) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

**Interpretation**: We do see a difference in proportion of heart attacks across the different categories of BMI. Obese group is having the highest proportion of having heart attack followed by underweight. Normal group has the lowest proportion of having heart attack.
<br><br>

**(b)** Heart Attack vs. Sex

Distribution of heart attack across sex groups is calculated and visualized as described above.

```{r}
#Table
prop.table(table(df_clean$HeartAttack, df_clean$SEX), margin = 2)

#Bar graph
ggplot(df_clean, aes(x = SEX, fill = HeartAttack)) +
  geom_bar(position = "fill") +
  ylab("Proportion") +
  xlab("Sex") +
  labs(fill = "Heart Attack Status") +
  ggtitle("Proportion of Heart Attack by Sex") +
  scale_fill_manual(values = custom_colors) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```
<br><br>

**(c)** Heart Attack vs. Income Level

Distribution of heart attack across income levels is calculated and visualized as described above.

```{r}

#Table
prop.table(table(df_clean$HeartAttack, df_clean$INCOME), margin = 2)

#Bar graph
ggplot(df_clean, aes(x = INCOME, fill = HeartAttack)) +
  geom_bar(position = "fill") +
  ylab("Proportion") +
  xlab("Income Level") +
  labs(fill = "Heart Attack Status") +
  ggtitle("Proportion of Heart Attack by Income Level") +
  scale_fill_manual(values = custom_colors) +
  scale_x_discrete(limits = c("<$10k", "$10-15k", "$15-20k", "$20-25k", "$25-35k", "$35-50k", "$50-75k", ">=75k")) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```
<br><br>

**(d)** Heart Attack vs. Race

Distribution of heart attack across race groups is calculated and visualized as described above.

```{r}
#Table
prop.table(table(df_clean$HeartAttack, df_clean$RACE), margin = 2)

#Bar graph
ggplot(df_clean, aes(x = RACE, fill = HeartAttack)) +
  geom_bar(position = "fill") +
  ylab("Proportion") +
  xlab("Race") +
  labs(fill = "Heart Attack Status") +
  ggtitle("Proportion of Heart Attack by Race") +
  scale_fill_manual(values = custom_colors) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```
<br><br>

**(e)** Heart Attack vs. Age

For distribution statistics and visualizing distribution of heart attack across age groups, we use categorical variable -- AGE. When using numeric version, the proportion is calculated for each numeric value. The resulting proportion may be hard to see, and the variation may not be significant. Contrarily, categorical version give us a better understanding of how distribution varies across main categorical levels.

```{r}
#Table
prop.table(table(df_clean$HeartAttack, df_clean$AGE), margin = 2)

#Bar graph
ggplot(df_clean, aes(x = AGE, fill = HeartAttack)) +
  geom_bar(position = "fill") +
  ylab("Proportion") +
  xlab("Age") +
  labs(fill = "Heart Attack Status") +
  ggtitle("Proportion of Heart Attack by Age") +
  scale_fill_manual(values = custom_colors) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```
<br><br>

#### 3) Conclusion

  Based on the correlation analysis, a positive correlation is observed between main predictor BMI and heart attack risks. When increasing BMI from normal group (BMI = 18.5-24.9) to obese group (BMI ≥ 30.0), the percentage of individuals with heart attack increases from 4.3% to 7.2%. This suggests BMI as a potential predictor of heart attack risks.
  
  Besides BMI, the proportion of individuals with heart attack also varies across categorical levels in all demographic variables. It indicates that all the demographic variables are potential confounding variables and must be controlled in the future model. Specifically, for **sex**, the proportion of males getting heart attack is higher than the proportion of females (0.078 vs. 0.042), suggesting males having higher risks of getting heart attack than females. For **age**, there is a strong positive correlation between age and the proportion of heart attacks. As the ages get higher and higher, the proportion also increases. For **income**, the proportion decreases as income level increases, suggesting a potential negative correlation between income level and odds of having heart attack. For **race**, Multiracial group is having the highest proportion of individuals with heart attack, and Hispanic group is having the lowest proportion of having heart attack.

### IV. Next Step

  In this project,  **HeartAttack** is selected as the response variable. Because it is a binary variable describing whether or not the respondent has heart attack (1=yes, 0=no), it will be logit transformed into logit (P(HeartAttack)). Logistic regression will be used for predicting odds of having heart attack.

  In the bar graphs, for each predictor, we visualize proportion of individuals with heart attack across different categories. Based on this preliminary analysis, we have observed correlations between 5 selected predictors with response variable **HeartAttack**. Significant predictors include **SEX**, **Income**, **AGE**,**Race**. Proportions of individuals with heart attack vary across different categorical levels, and it is observed in these predictors.  

  Specifically, we set **BMI** as the predictor in the main model. The significance of the predictor’s relationship with heart attack will be assessed using individual Z-tests. Other categorical factors will add as additive predictors in the extended model, which include **SEX**, **Income**, **Race**, and **Age**. Because they are categorical variables, we will analyze how the odds of having heart attack change when the category changes within each variable. Their overall contribution will first be evaluated using partial $\chi^2$ tests, and differences among levels of categorical predictors will be further examined through individual Z-tests. Only variables showing significant differences in heart attack odds across levels will be retained.
  
  Based on the significance results from both individual Z-tests and partial $\chi^2$ tests, the final extended model will be constructed. To ensure robustness, the final model will be assessed for influential data points using Cook’s distance and outlier tests for regression outliers. Multicollinearity between multiple predictors in the extensive models will be evaluated based on **Variance Inflation factor (VIF)**. The final model’s performance will be validated through goodness-of-fit measures: error rate test, which assess how well the model predicts the actual odds of heart attack.
<br><br>